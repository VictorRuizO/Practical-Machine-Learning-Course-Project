---
title: "Coursera Practical Machine Learning - Course Project"
output: html_document
---

*Victor Duvan Ruiz Ochoa*

*August 2020*


# Introduction

For this project, we are given data from accelerometers on the belt, forearm, arm, and dumbell of 6 research study participants. Our training data consists of accelerometer data and a label identifying the quality of the activity the participant was doing. Our testing data consists of accelerometer data without the identifying label. Our goal is to predict the labels for the test set observations.

Below is the code I used when creating the model, estimating the out-of-sample error, and making predictions. I also include a description of each step of the process.

# Data Preparation
First, let's include the libraries needed and set a seed.
```{r message=F, warning=F}
library(caret)
set.seed(112)
```
then, import the train a test data.

```{r}
ptrain <- read.csv("pml-training.csv")
ptest <- read.csv("pml-testing.csv")
```
Randomly split the full training data (ptrain) into a smaller training set (ptrain1) and a validation set (ptrain2):
```{r}
inTrain <- createDataPartition(y=ptrain$classe, p=0.7, list=F)
ptrain1 <- ptrain[inTrain, ]
ptrain2 <- ptrain[-inTrain, ]
```

For reduce the number of features by removing variables with nearly zero variance, variables that are almost always NA, and variables that don’t make intuitive sense for prediction. We decide which ones to remove by analyzing ptrain1, and perform the identical removals on ptrain2.

First remove variables with nearly zero variance
```{r}
nzv <- nearZeroVar(ptrain1)
ptrain1 <- ptrain1[, -nzv]
ptrain2 <- ptrain2[, -nzv]
```

Then remove variables whit so much NA values
```{r}
mostlyNA <- sapply(ptrain1, function(x) mean(is.na(x))) > 0.95
ptrain1 <- ptrain1[, mostlyNA==F]
ptrain2 <- ptrain2[, mostlyNA==F]
```

By last remove variables that don't make intuitive sense for prediction (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp).
```{r}
ptrain1 <- ptrain1[, -(1:5)]
ptrain2 <- ptrain2[, -(1:5)]
```

# Model Building
To see if it would have acceptable performance, I decided to start with a Random Forest model. I fit the model on ptrain1, and instruct the “train” function to use 3-fold cross-validation to select optimal tuning parameters for the model.

```{r cache=F}
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit <- train(classe ~ ., data=ptrain1, method="rf", trControl=fitControl)
```

Let's see the final model and the parameters that it chose
```{r}
fit$finalModel
```
Whit this information I decided to use 500 trees and try 27 variables at each split.

# Model Evaluation and Selection
Let's use the fitted model to predict the label *classe* in ptrain2, and show the confusion matrix.

```{r}
preds <- predict(fit, newdata=ptrain2)
confusionMatrix(table(ptrain2$classe, preds))
```

How we can see, the accuracy is 99.8%, thus the predicted accuracy for the out-of-sample error is 0.2%.

This is an excellent result, so rather than trying additional algorithms, let's try to use Random Forests to predict on the test set.

# Re-training
Let's train the model on the full training set *ptrain*.

First, remove variables with nearly zero variance.

```{r}
nzv <- nearZeroVar(ptrain)
ptrain <- ptrain[, -nzv]
ptest <- ptest[, -nzv]
```

Then, remove variables whit so much NA values
```{r}
mostlyNA <- sapply(ptrain, function(x) mean(is.na(x))) > 0.95
ptrain <- ptrain[, mostlyNA==F]
ptest <- ptest[, mostlyNA==F]
```

By last remove variables that don't make intuitive sense for prediction (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp).

```{r}
ptrain <- ptrain[, -(1:5)]
ptest <- ptest[, -(1:5)]
```

Re-fit model using full training set (ptrain)
```{r cache=F}
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
fit2 <- train(classe ~ ., data=ptrain, method="rf", trControl=fitControl)
```

# Making test predictions
Let's use the model fit on ptrain to predict the label for the observations in ptest.
```{r}
preds <- predict(fit2, newdata=ptrain2)
confusionMatrix(table(ptrain2$classe, preds))
```


